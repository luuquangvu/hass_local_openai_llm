{
  "config": {
    "step": {
      "user": {
        "title": "Configure Local OpenAI Server",
        "data": {
          "server_name": "Server Name",
          "base_url": "Server URL",
          "api_key": "API key"
        }
      }
    },
    "error": {
      "cannot_connect": "Could not communicate with the server",
      "unknown": "An unknown error occurred"
    },
    "abort": {
      "already_configured": "Already configured"
    }
  },
  "config_subentries": {
    "conversation": {
      "step": {
        "user": {
          "title": "Configure the new conversation agent",
          "data": {
            "model": "Model",
            "prompt": "System Prompt",
            "llm_hass_api": "Tool Providers",
            "strip_emojis": "Strip emojis from the response",
            "strip_emphasis": "Strip Markdown emphasis markers from the response",
            "suggested_value": "Suggested value",
            "temperature": "Temperature",
            "max_message_history": "Maximum message history size (0 means no limit)",
            "manual_prompting": "Full manual prompting",
            "parallel_tool_calls": "Parallel tool calling"
          },
          "data_description": {
            "model": "The model to use for the conversation agent",
            "prompt": "Instruct how the LLM should respond. This can be a template."
          }
        },
        "reconfigure": {
          "title": "Reconfigure the conversation agent",
          "data": {
            "model": "Model",
            "prompt": "System Prompt",
            "llm_hass_api": "Tool Providers",
            "strip_emojis": "Strip emojis from the response",
            "strip_emphasis": "Strip Markdown emphasis markers from the response",
            "suggested_value": "Suggested value",
            "temperature": "Temperature",
            "max_message_history": "Maximum message history size (0 means no limit)",
            "manual_prompting": "Full manual prompting",
            "parallel_tool_calls": "Parallel tool calling"
          },
          "data_description": {
            "model": "The model to use for the conversation agent",
            "prompt": "Instruct how the LLM should respond. This can be a template."
          }
        }
      },
      "initiate_flow": {
        "user": "Add conversation agent"
      },
      "entry_type": "Conversation agent",
      "abort": {
        "cannot_connect": "Could not communicate with the server",
        "unknown": "An unknown error occurred",
        "reconfigure_successful": "Conversation Agent has been reconfigured"
      }
    },
    "ai_task_data": {
      "step": {
        "user": {
          "data": {
            "model": "The model to use for the AI Task agent"
          }
        }
      },
      "initiate_flow": {
        "user": "Add AI task"
      },
      "entry_type": "AI task",
      "abort": {
        "cannot_connect": "Could not communicate with the server",
        "unknown": "An unknown error occurred",
        "reconfigure_successful": "AI Task Agent has been reconfigured"
      }
    }
  },
  "options": {
    "step": {
      "reconfigure": {
        "title": "Reconfigure the conversation agent",
        "data": {
          "model": "Model",
          "prompt": "System Prompt",
          "llm_hass_api": "Tool Providers",
          "strip_emojis": "Strip emojis from the response",
          "strip_emphasis": "Strip Markdown emphasis markers from the response",
          "suggested_value": "Suggested value",
          "temperature": "Temperature",
          "max_message_history": "Maximum message history size (0 means no limit)",
          "manual_prompting": "Full manual prompting",
          "parallel_tool_calls": "Parallel tool calling"
        },
        "data_description": {
          "model": "The model to use for the conversation agent",
          "prompt": "Instruct how the LLM should respond. This can be a template."
        }
      }
    }
  },
  "exceptions": {
    "unsupported_attachment_type": "This model does not support the attached file type."
  }
}
